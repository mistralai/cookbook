{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggsmith842/cookbook/blob/main/third_party/ChromaDB/chroma_mistral_embed_fn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3pCegZ90M0_"
      },
      "source": [
        "# ✨ Using Mistral-Embed with ChromaDB\n",
        "\n",
        "> **Author:** Grant Smith  \n",
        "> **GitHub:** [ggsmith842](https://github.com/ggsmith842)\n",
        "\n",
        "---\n",
        "\n",
        "This notebook walks through how to use MistralAI's `mistral-embed` model as a custom embedding function in the ChromaDB vector database.\n",
        "\n",
        "### Documentation Links\n",
        "1. [ChromaDB Documentation](https://docs.trychroma.com/docs/overview/introduction)\n",
        "2. [Mistral Embeddings](https://docs.mistral.ai/capabilities/embeddings/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UxjUWKIcau0Q"
      },
      "outputs": [],
      "source": [
        "%pip install chromadb mistralai -Uq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzA1X68hbxmF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "import chromadb\n",
        "\n",
        "from mistralai import Mistral\n",
        "from datetime import datetime\n",
        "\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90jMUU67ScJu",
        "outputId": "09d5e6ee-cd08-4b74-f130-10193188919e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your mistralai api key:··········\n"
          ]
        }
      ],
      "source": [
        "if os.environ.get('MISTRAL_API_KEY'):\n",
        "  api_key = os.environ['MISTRAL_API_KEY']\n",
        "else:\n",
        "  api_key = getpass.getpass(\"Please provide your mistralai api key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Uv7HAXlTdx_N"
      },
      "outputs": [],
      "source": [
        "# create a temp client that only lasts for the current session\n",
        "client = chromadb.EphemeralClient()\n",
        "\n",
        "# create a persistent client that can be used after session ends\n",
        "# client = chromadb.PersistentClient(path = os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vxczzoq7hQht"
      },
      "outputs": [],
      "source": [
        "# create custom embedding function using mistral-embed\n",
        "class MistralEmbedFn(EmbeddingFunction):\n",
        "\n",
        "    def __init__(self, api_key: str = None) -> None:\n",
        "        if api_key:\n",
        "            self.api_key = api_key\n",
        "        else:\n",
        "          try:\n",
        "            self.api_key = getpass.getpass(\"Please provide your MistralAi API Key:\")\n",
        "          except Exception as e:\n",
        "            print(f'Error getting API key from user: {e}')\n",
        "\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        client = Mistral(api_key=self.api_key)\n",
        "        try:\n",
        "          embeddings = [e.embedding for e in (client.embeddings.create(model='mistral-embed', inputs = input)).data]\n",
        "          return embeddings\n",
        "        except Exception as e:\n",
        "          print(f'An error occured getting embeddings from model: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjdfa9S4fxgN",
        "outputId": "8c65dba6-52d2-447b-abbc-bb8337ae1dda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your MistralAi API Key:··········\n"
          ]
        }
      ],
      "source": [
        "# instantiate embedding function to use in collection\n",
        "embed_fn = MistralEmbedFn(api_key=api_key)\n",
        "\n",
        "# create collection\n",
        "collection = client.create_collection(\n",
        "    name=\"quotes\",\n",
        "    embedding_function = embed_fn, #MistralEmbedFn(),\n",
        "    metadata={\n",
        "        \"description\": \"Quotes about Computer Science\",\n",
        "        \"created\": str(datetime.now())\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Sy87VPBzpEZl"
      },
      "outputs": [],
      "source": [
        "# add data to collection\n",
        "collection.add(\n",
        "    documents=[\n",
        "        \"A new, a vast, and a powerful language is developed for the future use of analysis, in which to wield its truths so that these may become of more speedy and accurate practical application for the purposes of mankind than the means hitherto in our possession have rendered possible.\",\n",
        "        \"A computer would deserve to be called intelligent if it could deceive a human into believing that it was human.\"\n",
        "    ],\n",
        "    metadatas = [{\"attribution\": \"Ada Lovelace\"}, {\"attribution\": \"Alan Turing\"}],\n",
        "    ids = [f'id{i}' for i in range(2)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRExyp4hnoAK",
        "outputId": "28b5a48b-407a-4e87-a4d3-b13a89ca6f6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ids': ['id0', 'id1'],\n",
              " 'embeddings': array([[-0.00104618,  0.03088379,  0.06524658, ..., -0.02191162,\n",
              "          0.00763321, -0.02656555],\n",
              "        [-0.05441284,  0.0423584 ,  0.02516174, ..., -0.00370789,\n",
              "         -0.00035167, -0.00721359]]),\n",
              " 'documents': ['A new, a vast, and a powerful language is developed for the future use of analysis, in which to wield its truths so that these may become of more speedy and accurate practical application for the purposes of mankind than the means hitherto in our possession have rendered possible.',\n",
              "  'A computer would deserve to be called intelligent if it could deceive a human into believing that it was human.'],\n",
              " 'uris': None,\n",
              " 'included': ['metadatas', 'documents', 'embeddings'],\n",
              " 'data': None,\n",
              " 'metadatas': [{'attribution': 'Ada Lovelace'},\n",
              "  {'attribution': 'Alan Turing'}]}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# peek at collection\n",
        "collection.peek()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN5EYUDJCneDwXQGMvJA7BY",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
